{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 716/716 [00:00<00:00, 1.76MB/s]\n"
     ]
    }
   ],
   "source": [
    "dataset= load_dataset('sehyun66/Finnhub-News',split='train')\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=list(df['headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(texts, padding=True ,truncation=True,return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "print(model.config.id2label[predicted_class_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 504/504 [04:37<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 1024  # Adjust this value as needed\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through the input data in chunks\n",
    "for i in tqdm(range(0, len(inputs['input_ids']), chunk_size)):\n",
    "    chunk = inputs['input_ids'][i:i+chunk_size]\n",
    "    chunk.to(device)\n",
    "    # Perform inference on the chunk\n",
    "    with torch.no_grad():\n",
    "        output = model(chunk).logits   \n",
    "    # Append the output to the results list\n",
    "    results.append(output)\n",
    "\n",
    "# Concatenate or process the results as needed\n",
    "final_output = torch.cat(results, dim=0)  # Concatenate along the appropriate dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_output, 'sentiment_data/finbert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6055, -0.4091,  0.8146], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['sentiment'] = final_output.to('cpu').tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_name'] = df['sentiment'].apply(lambda x:{'postive':x[0],'negative':x[1],'neutral':x[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sentiment_data/finbert.json'\n",
    "json_data = df.to_json(orient='records')\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1106.09it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 467.75it/s]\n",
      "Generating train split: 515851 examples [00:11, 45993.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\n",
    "        \"json\",\n",
    "        data_files={\n",
    "            \"train\": \"/home/ssu36/tiger/NH_competition/sentiment_data/*.json\"\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 516/516 [00:01<00:00, 411.96ba/s]\n"
     ]
    }
   ],
   "source": [
    "ds.push_to_hub('sehyun66/Finnhub-News')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
